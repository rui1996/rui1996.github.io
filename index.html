<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Rui Qian's Home page.">
    <meta name="author" content="Rui Qian">
    <link rel="icon" href="images/Simsimmi.jpeg">

    <title>Rui Qian </title>

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="css/narrow-jumbotron.css" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-111714927-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-111714927-1');
    </script>

</head>

<body>

<div class="container">

    <main role="main">

        <div id="about" class="row marketing">

                <div class="col-lg-5">
                    <figure class="figure">
                        <img src="images/myself.jpg" class="figure-img img-fluid rounded" alt="Me.">
                    </figure>
                </div>
                <div class="col-lg-6 offset-lg-1">
                    <div class="row marketing" style="margin-top:0">
                        <h2>Rui Qian (钱瑞)</h2>
                    </div>
                    <div class="row marketing">
                        <p>I am a staff research scientist at Apple AI/ML foundation model team. Before joining Apple, I was a research scientist at Google. 
                        <br>
                        <br>
                        I received Ph.D. in Computer Science from 
                        <a href="http://cornell.edu/">Cornell University</a> and <a href="https://tech.cornell.edu/">Cornell Tech</a>, advised by Prof.
                        <a href="https://vision.cornell.edu/se3/people/serge-belongie/">Serge Belongie</a>. Prior to Cornell, I received the B.S. in Computer Science with Summa Cum Laude from 
                        <a href="http://english.pku.edu.cn/">Peking University</a>.
                        <br>
                        <br>
                         I'm interested in contributing to industrial-scale generative models, like <a href="https://deepmind.google/technologies/imagen-3/">Imagen3</a> and <a href="https://deepmind.google/technologies/veo/">Veo</a>. I am honored to have received the 2023 Google Research PA Tech Impact Award.
                        </p>
                    </div>
                    <div class="row marketing">
                        <p><b>Email: </b>rq49@cornell.edu </br>
                        [<a href="https://github.com/rui1996">Github</a>]
                        [<a href="https://scholar.google.com.sg/citations?user=HrzHNbAAAAAJ&hl=en">Google Scholar</a>]
                        [<a href="https://www.linkedin.com/in/rui-qian-64809315b/">Linkedin</a>]
                        </p>
                    </div>
                </div>
        </div>
        <div class="row marketing">
            <!--Place holder-->
        </div>

        <div id="projects" class="row marketing">
            <div class="row" style="width:100%">
                <div class="col-lg-12">
                    <h2>Industrial Research</h2>
                    <hr>
                </div>
            </div>

            <div class="row marketing">
                <div class="col-lg-6 mt-4">
                    <img class="img-thumbnail" src="images/industry/imagen3.png" style="width:100%;max-height:270px"/>
                </div>

                <div class="col-lg-6">
                    <h5><span class="font-italic">(Launched@Google I/O 2024)</span><br>
                        Imagen 3: Google's highest quality text-to-image model<br>
                        [<a href="https://deepmind.google/technologies/imagen-3/">AI Blog</a>]
                    </h5>
                    <p>Google GenMedia Team: <b>Rui Qian, core contributor</b></p> 
                </div>

            <div class="row marketing">
                <div class="col-lg-6 mt-4">
                    <img class="img-thumbnail" src="images/industry/veo.png" style="width:100%;max-height:270px"/>
                </div>

                <div class="col-lg-6">
                    <h5><span class="font-italic">(Launched@Google I/O 2024)</span><br>
                        Veo: Google's most capable video generation model to date with capbility of generating minutes long 1080p resolution videos<br>
                        [<a href="https://deepmind.google/technologies/veo/">AI Blog</a>]
                    </h5>
                    <p>Google GenMedia Team: <b>Rui Qian, core contributor</b></p> 
                </div>
            </div>

            <div class="row marketing">
                <div class="col-lg-6 mt-4">
                    <img class="img-thumbnail" src="images/industry/videoprism.png" style="width:100%;max-height:270px"/>
                </div>

                <div class="col-lg-6">
                    <h5><span class="font-italic">(ICML 2024)</span><br>
                        VideoPrism: A foundational visual encoder for video understanding<br>
                        [<a href="https://research.google/blog/videoprism-a-foundational-visual-encoder-for-video-understanding/">AI Blog</a>][<a href="https://arxiv.org/abs/2402.13217">Paper</a>]
                    </h5>
                    <p>Google Research: <b>Rui Qian, contributor</b></p> 
                </div>
            </div>

        </div>

        <div id="Place holder" class="row marketing">
        <!--Place holder-->
        </div>

        <div id="projects" class="row marketing">
            <div class="row" style="width:100%">
                <div class="col-lg-12">
                    <h2>Selected Publications</h2>
                    <hr>
                </div>
            </div>

            <div class="row marketing">
                <div class="col-lg-6 mt-4">
                    <img class="img-thumbnail" src="images/publication/ssw.png" style="width:100%;max-height:200px"/>
                </div>

                <div class="col-lg-6">
                    <h5><span class="font-italic">(ECCV 2022)</span><br>
                        Exploring Fine-grained Audiovisual Categorization<br>
                        [<a href="https://arxiv.org/abs/2207.10664">Paper</a>][<a href="https://github.com/visipedia/ssw60">Code</a>][<a href="https://github.com/visipedia/ssw60">Dataset</a>]
                    </h5>
                    <p><b>Rui Qian</b>, Kimberly Wilber, Hartwig Adam, Oisin Mac Aodha, Serge Belongie, Grant Van Horn</p>
                </div>
            </div>

            <div class="row marketing">
                <div class="col-lg-6 mt-4">
                    <img class="img-thumbnail" src="images/publication/teg.png" style="width:100%;max-height:200px"/>
                </div>

                <div class="col-lg-6">
                    <h5><span class="font-italic">(BMVC 2022)</span><br>
                        Exploring Temporal Granularity in Self-Supervised Video Representation Learning<br>
                        [<a href="https://arxiv.org/abs/2112.04480">Paper</a>]
                    </h5>
                    <p><b>Rui Qian</b>, Yeqing Li, Liangzhe Yuan, Boqing Gong, Ting Liu, Matthew Brown, Serge Belongie, Ming-Hsuan Yang, Hartwig Adam, Yin Cui</p> 
                </div>
            </div>

            <div class="row marketing">
                <div class="col-lg-6 mt-4">
                    <img class="img-thumbnail" src="images/publication/chr.png" style="width:100%;max-height:200px"/>
                </div>

                <div class="col-lg-6">
                    <h5><span class="font-italic">(CVPR 2022)</span><br>
                        Contextualized Spatio-Temporal Contrastive Learning with Self-Supervision<br>
                        [<a href="https://arxiv.org/abs/2112.05181">Paper</a>]
                    </h5>
                    <p>Liangzhe Yuan, <b>Rui Qian</b>, Yin Cui, Boqing Gong, Florian Schroff, Ming-Hsuan Yang, Hartwig Adam, Ting Liu</p> 
                </div>
            </div>

            <div class="row marketing">
                <div class="col-lg-6 mt-4">
                    <img class="img-thumbnail" src="images/publication/cvrl.png" style="max-width:100%;max-height:200px"/>
                </div>

                <div class="col-lg-6">
                    <h5><span class="font-italic">(CVPR 2021)</span><br>
                        Spatiotemporal Contrastive Video Representation Learning<br>
                        [<a href="https://arxiv.org/abs/2008.03800">Paper</a>][<a href="https://github.com/tensorflow/models/tree/master/official/vision/beta/projects/video_ssl">Code</a>]
                    </h5>
                    <p><b>Rui Qian*</b>, Tianjian Meng*, Boqing Gong, Ming-Hsuan Yang, Huisheng Wang, Serge Belongie, Yin Cui</p> 
                </div>
            </div>

            <div class="row marketing">
                <div class="col-lg-6 mt-4">
                    <img class="img-thumbnail" src="images/publication/copypaste.png" style="max-width:100%;max-height:200px"/>
                </div>

                <div class="col-lg-6">
                    <h5><span class="font-italic">(CVPR 2021, Oral)</span><br>
                        Simple Copy-Paste is a Strong Data Augmentation Method for Instance Segmentation<br>
                        [<a href="https://arxiv.org/abs/2012.07177">Paper</a>][<a href="https://github.com/tensorflow/tpu/tree/master/models/official/detection/projects/copy_paste">Code</a>]
                    </h5>
                    <p>Golnaz Ghiasi*, Yin Cui*, Aravind Srinivas*, <b>Rui Qian</b>, Tsung-Yi Lin, Ekin D. Cubuk, Quoc V. Le, Barret Zoph</p> 
                </div>
            </div>

            <div class="row marketing">
                <div class="col-lg-6 mt-4">
                    <img class="img-thumbnail" src="images/publication/vatt.png" style="max-width:100%;max-height:200px"/>
                </div>

                <div class="col-lg-6">
                    <h5><span class="font-italic">(NeurIPS 2021)</span><br>
                        VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text<br>
                        [<a href="https://arxiv.org/abs/2104.11178">Paper</a>][<a href="https://github.com/google-research/google-research/tree/master/vatt">Code</a>]
                    </h5>
                    <p>Hassan Akbari, Liangzhe Yuan, <b>Rui Qian</b>, Wei-Hong Chuang, Shih-Fu Chang, Yin Cui, Boqing Gong</p> 
                </div>
            </div>

            <div class="row marketing">
                <div class="col-lg-6 mt-4">
                    <img class="img-thumbnail" src="images/publication/pl_e2e.png" style="max-width:100%;max-height:200px"/>
                </div>

                <div class="col-lg-6">
                    <h5><span class="font-italic">(CVPR 2020)</span><br>
                        End-to-end Pseudo-LiDAR for Image-Based 3D Object Detection<br>
                        [<a href="https://arxiv.org/abs/2004.03080">Paper</a>][<a href="https://github.com/mileyan/pseudo-LiDAR_e2e">Code</a>]
                    </h5>
                    <p><b>Rui Qian*</b>, Divyansh Garg*, Yan Wang*, Yurong You*, Serge Belongie, Bharath Hariharan, Mark Campbell, Kilian Weinberger, Wei-Lun Chao</p> 
                </div>
            </div>

            <div class="row marketing">
                <div class="col-lg-6 mt-4">
                    <img class="img-thumbnail" src="images/publication/point.png" style="width:100%;max-height:200px"/>
                </div>

                <div class="col-lg-6">
                    <h5><span class="font-italic">(AAAI 2019, Spotlight)</span><br>
                        Weakly Supervised Scene Parsing with Point-Based Distance Metric Learning<br>
                        [<a href="https://arxiv.org/abs/1811.02233">Paper</a>]
                    </h5>
                    <p><b>Rui Qian</b>, Yunchao Wei, Honghui Shi, Jiachen Li, Jiaying Liu, Thomas Huang</p> 
                </div>
            </div>

            <div class="row marketing">
                <div class="col-lg-6 mt-4">
                    <img class="img-thumbnail" src="images/publication/raindrop.png" style="width:100%;max-height:200px"/>
                </div>

                <div class="col-lg-6">
                    <h5><span class="font-italic">(CVPR 2018, Spotlight)</span><br>
                        Attentive Generative Adversarial Network for Raindrop Removal from A Single Image<br>
                        [<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Qian_Attentive_Generative_Adversarial_CVPR_2018_paper.pdf">Paper</a>][<a href="https://github.com/rui1996/DeRaindrop">Code</a>][<a href="https://drive.google.com/open?id=1e7R76s6vwUJxILOcAsthgDLPSnOrQ49K">Dataset</a>]
                    </h5>
                    <p><b>Rui Qian</b>, Robby T. Tan, Wenhan Yang, Jiajun Su, Jiaying Liu</p> 
                </div>
            </div>

        </div>

        <div id="Place holder" class="row marketing">
        <!--Place holder-->
        </div>

        <div id="Place holder" class="row marketing">
        <!--Place holder-->
        </div>

        <div id="experiences" class="row marketing">
            <div class="row" style="width:100%">
                <div class="col-lg-12">
                    <h2>Experiences</h2>
                    <hr>
                </div>
            </div>

            <div class="row marketing">
                <div class="col-lg-4">
                    <img class="img-thumbnail" src="images/experience/google_logo.png"  style="width:100%;max-height:300px;max-width:300px"/>
                </div>
                <div class="col-lg-8">
                    <h5>Google Research</h5>
                    <p>Research Intern<br>
                    May 2022 - Aug 2022 <br>
                    Host: Dr. <a href="https://ycui.me/">Yin Cui</a>, Dr. <a href="http://boqinggong.info/">Boqing Gong</a>, <br>  
                    Dr. <a href="https://scholar.google.com/citations?user=_BPdgV0AAAAJ&hl=zh-CN">Tsung-Yi Lin</a>, Prof. <a href="http://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a></p>
                </div>
            </div>

            <div class="row marketing">
                <div class="col-lg-4">
                    <img class="img-thumbnail" src="images/experience/bytedance_logo.png"  style="width:100%;max-height:300px;max-width:300px"/>
                </div>
                <div class="col-lg-8">
                    <h5>Bytedance AI Research</h5>
                    <p>Research Intern<br>
                    Mar 2019 - Jul 2019<br>
                    Host: Dr. <a href="https://scholar.google.com/citations?user=PGtHUI0AAAAJ&hl=en">Ding Liu</a>, Dr. <a href="http://users.eecs.northwestern.edu/~xsh835/">Xiaohui Shen</a></p>
                </div>
            </div>

            <div class="row marketing">
                <div class="col-lg-4">
                    <img class="img-thumbnail" src="images/experience/microsoft_logo.png"  style="width:100%;max-height:380px;max-width:380px"/>
                </div>
                <div class="col-lg-8">
                    <h5>Microsoft Research</h5>
                    <p>Research Intern<br>
                    Sept 2018 - Mar 2019<br>
                    Host: Dr. <a href="https://www.microsoft.com/en-us/research/people/stevelin/">Stephen Lin</a></p>
                </div>
            </div>

            <div class="row marketing" style="width:100%">
                <!--Place holder-->
                <hr>
            </div>

        </div>

        <div id="misc" class="row marketing">
            <div class="row" style="width:100%">
                <div class="col-lg-12">
                    <h2>Misc</h2>
                    <hr>
                </div>
            </div>
            I really love my workspace at Cornell Tech which has 180 degree view of Manhattan (day and night).
            <div class="row marketing">
                <div class="col-lg-4">
                    <img class="img-thumbnail" src="images/misc/day_view.jpeg"  style="max-height:500px;max-width:500px"/>
                </div>
            </div>

            <div class="row marketing">
                <div class="col-lg-4">
                    <img class="img-thumbnail" src="images/misc/night.jpeg"  style="max-height:500px;max-width:500px"/>
                </div>
            </div>
            <div class="row marketing" style="width:100%">
                <!--Place holder-->
                <hr>
            </div>
            Here is the view from the House at Cornell Tech (summer and winter).
            <div class="row marketing" style="width:100%">
                <!--Place holder-->
                <hr>
            </div>
            <div class="row marketing">
                <div class="col-lg-4">
                    <img class="img-thumbnail" src="images/misc/summer.jpeg"  style="max-height:500px;max-width:500px"/>
                </div>
            </div>

            <div class="row marketing">
                <div class="col-lg-4">
                    <img class="img-thumbnail" src="images/misc/winter.jpeg"  style="max-height:500px;max-width:500px"/>
                </div>
            </div>
            <div class="row marketing" style="width:100%">
                <!--Place holder-->
                <hr>
            </div>
        </div>

        

    </main>

    <footer class="footer">
    <p>&copy; Rui Qian 2024</p>
    </footer>

</div> <!-- /container -->
</body>
</html>
